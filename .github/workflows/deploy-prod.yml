---
name: Deploy to Production Pis

on:
  workflow_dispatch:
    inputs:
      playbook:
        description: 'Playbook to run'
        required: true
        default: '10-base.yml'
        type: choice
        options:
          - '00-bootstrap.yml'
          - '10-base.yml'
          - '20-podman.yml'
          - '30-observability.yml'
          - '40-ingress.yml'
          - '50-secrets-sso.yml'
      target:
        description: 'Deployment target'
        required: true
        default: 'canary'
        type: choice
        options:
          - 'canary'  # pi-a only
          - 'full'    # all pis
      force:
        description: 'Skip safety checks (USE WITH CAUTION)'
        required: false
        type: boolean
        default: false

jobs:
  safety-checks:
    name: Production Safety Checks
    runs-on: ubuntu-latest
    outputs:
      proceed: ${{ steps.safety.outputs.proceed }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Verify staging deployment
        id: safety
        run: |
          echo "Checking production deployment safety..."
          echo "Target: ${{ inputs.target }}"
          echo "Playbook: ${{ inputs.playbook }}"

          if [ "${{ inputs.force }}" == "true" ]; then
            echo "::warning::Force flag enabled - bypassing safety checks!"
            echo "proceed=true" >> $GITHUB_OUTPUT
          else
            # In real deployment, check staging status here
            echo "proceed=true" >> $GITHUB_OUTPUT
          fi

  canary-deploy:
    name: Canary Deployment (pi-a)
    runs-on: ubuntu-latest
    needs: safety-checks
    if: needs.safety-checks.outputs.proceed == 'true'
    environment:
      name: production
      url: https://pi-a.homelab.local
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Connect to Tailscale
        uses: tailscale/github-action@v3
        with:
          oauth-client-id: ${{ secrets.TS_OAUTH_CLIENT_ID }}
          oauth-secret: ${{ secrets.TS_OAUTH_SECRET }}
          tags: tag:ci,tag:prod
          version: stable

      - name: Install Ansible
        run: |
          pip install --upgrade pip
          pip install ansible
          ansible-galaxy collection install containers.podman community.general ansible.posix

      - name: Set up SSH key
        env:
          SSH_PRIVATE_KEY: ${{ secrets.ANSIBLE_SSH_PRIVATE_KEY }}
        run: |
          mkdir -p ~/.ssh
          echo "$SSH_PRIVATE_KEY" > ~/.ssh/id_rsa
          chmod 600 ~/.ssh/id_rsa
          cat >> ~/.ssh/config <<EOF
          Host pi-* *.local
            StrictHostKeyChecking no
            UserKnownHostsFile=/dev/null
            User william
            IdentityFile ~/.ssh/id_rsa
          EOF
          chmod 600 ~/.ssh/config

      - name: Preflight - Time sync check
        run: |
          echo "Checking time synchronization on canary..."
          ansible -i ansible/inventories/prod/hosts.yml canary \
            -m shell -a '
              if chronyc tracking | grep -q "Leap status.*Normal"; then
                offset=$(chronyc tracking | awk "/Last offset/ {print (\$4<0?-1*\$4:\$4)}")
                stratum=$(chronyc tracking | awk "/Stratum/ {print \$3}")
                offset_ms=$(echo "$offset * 1000" | bc -l)
                if (( $(echo "$offset_ms < 100" | bc -l) )) && [ "$stratum" -le 3 ]; then
                  echo "Time sync OK: offset=${offset_ms}ms, stratum=${stratum}"
                  exit 0
                else
                  echo "Time sync FAILED: offset=${offset_ms}ms, stratum=${stratum}"
                  exit 1
                fi
              else
                echo "Chrony not synchronized"
                exit 1
              fi
            '
        continue-on-error: ${{ inputs.force == true }}

      - name: Preflight - SSH redundancy check
        run: |
          echo "Verifying SSH redundancy..."
          ./scripts/preflight_ssh.sh pi-a || [ "${{ inputs.force }}" == "true" ]

      - name: Deploy to canary (pi-a)
        run: |
          ansible-playbook \
            -i ansible/inventories/prod/hosts.yml \
            ansible/playbooks/${{ inputs.playbook }} \
            --limit canary \
            -e "serial=1"

      - name: Canary health check
        run: |
          echo "Waiting for services to stabilize..."
          sleep 30
          ansible -i ansible/inventories/prod/hosts.yml canary \
            -m shell -a 'systemctl is-system-running || true'

          # Check specific services if observability playbook was run
          if [ "${{ inputs.playbook }}" == "30-observability.yml" ]; then
            ./scripts/verify_services.sh pi-a || true
          fi

  full-rollout:
    name: Full Production Rollout
    runs-on: ubuntu-latest
    needs: canary-deploy
    if: inputs.target == 'full'
    environment:
      name: production-full
      url: https://homelab.local
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Connect to Tailscale
        uses: tailscale/github-action@v3
        with:
          oauth-client-id: ${{ secrets.TS_OAUTH_CLIENT_ID }}
          oauth-secret: ${{ secrets.TS_OAUTH_SECRET }}
          tags: tag:ci,tag:prod
          version: stable

      - name: Install Ansible
        run: |
          pip install --upgrade pip
          pip install ansible
          ansible-galaxy collection install containers.podman community.general ansible.posix

      - name: Set up SSH key
        env:
          SSH_PRIVATE_KEY: ${{ secrets.ANSIBLE_SSH_PRIVATE_KEY }}
        run: |
          mkdir -p ~/.ssh
          echo "$SSH_PRIVATE_KEY" > ~/.ssh/id_rsa
          chmod 600 ~/.ssh/id_rsa
          cat >> ~/.ssh/config <<EOF
          Host pi-* *.local
            StrictHostKeyChecking no
            UserKnownHostsFile=/dev/null
            User william
            IdentityFile ~/.ssh/id_rsa
          EOF
          chmod 600 ~/.ssh/config

      - name: Deploy to remaining Pis (pi-b, pi-c)
        run: |
          ansible-playbook \
            -i ansible/inventories/prod/hosts.yml \
            ansible/playbooks/${{ inputs.playbook }} \
            --limit 'production:!canary' \
            -e "serial=1"

      - name: Full cluster health check
        run: |
          echo "Verifying full cluster health..."
          ansible -i ansible/inventories/prod/hosts.yml production \
            -m shell -a 'systemctl is-system-running || true'

          if [ "${{ inputs.playbook }}" == "30-observability.yml" ]; then
            ./scripts/verify_services.sh pi-a pi-b pi-c || true
          fi

      - name: Create deployment summary
        if: always()
        run: |
          echo "## Deployment Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Playbook**: ${{ inputs.playbook }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Target**: ${{ inputs.target }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Force Mode**: ${{ inputs.force }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Timestamp**: $(date -u +"%Y-%m-%d %H:%M:%S UTC")" >> $GITHUB_STEP_SUMMARY
